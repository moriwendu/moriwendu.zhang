	分布式系统两个基础理论：CAP/BASE
		CAP：AP
			C、A、P：三者其中之二；
				AP：可用性、分区容错性、弱一致性；
		BASE：BA，S，E
			BA：基本可用、S：软状态、E：最终一致性；
			
	分布式系统：	
		分布式存储：
			NoSQL：
				kv、document、column families、GraphDB
			分布式文件系统：文件系统接口
				分布式存储：API，不能挂载；				            		
            NewSQL：
                PingCAP：TiDB(MySQL protocol)...
		分布式运算：mapreduce, ...
		
	redis：REmote DIctionary Server
		数据结构：String, List, Set, sorted_set, Hash, pubsub ...
		

[root@CentOS profile.d]# rpm -ql redis
/etc/logrotate.d/redis
/etc/redis-sentinel.conf
/etc/redis.conf
/etc/systemd/system/redis-sentinel.service.d
/etc/systemd/system/redis-sentinel.service.d/limit.conf
/etc/systemd/system/redis.service.d
/etc/systemd/system/redis.service.d/limit.conf
/usr/bin/redis-benchmark
/usr/bin/redis-check-aof
/usr/bin/redis-check-rdb
/usr/bin/redis-cli         --> 命令行连接工具
/usr/bin/redis-sentinel    --> 使用于主从复制的.
/usr/bin/redis-server
/usr/lib/systemd/system/redis-sentinel.service
/usr/lib/systemd/system/redis.service
/usr/libexec/redis-shutdown
/usr/share/doc/redis-3.2.10
/usr/share/doc/redis-3.2.10/00-RELEASENOTES
/usr/share/doc/redis-3.2.10/BUGS
/usr/share/doc/redis-3.2.10/CONTRIBUTING
/usr/share/doc/redis-3.2.10/MANIFESTO
/usr/share/doc/redis-3.2.10/README.md
/usr/share/licenses/redis-3.2.10
/usr/share/licenses/redis-3.2.10/COPYING
/usr/share/man/man1/redis-benchmark.1.gz
/usr/share/man/man1/redis-check-aof.1.gz
/usr/share/man/man1/redis-check-rdb.1.gz
/usr/share/man/man1/redis-cli.1.gz
/usr/share/man/man1/redis-sentinel.1.gz
/usr/share/man/man1/redis-server.1.gz
/usr/share/man/man5/redis-sentinel.conf.5.gz
/usr/share/man/man5/redis.conf.5.gz
/var/lib/redis    --> 放置数据
/var/log/redis    --> 放置日志
/var/run/redis

监听端口为: 127.0.0.1:6379

命令行用户工具:
    /usr/bin/redis-cli
    [root@CentOS profile.d]# redis-cli  -h
	redis-cli 3.2.10

	Usage: redis-cli [OPTIONS] [cmd [arg [arg ...]]]
	  -h <hostname>      Server hostname (default: 127.0.0.1).
	  -p <port>          Server port (default: 6379).
	  -s <socket>        Server socket (overrides hostname and port).
	  -a <password>      Password to use when connecting to the server.
	  -r <repeat>        Execute specified command N times.
	  -i <interval>      When -r is used, waits <interval> seconds per command.
	                     It is possible to specify sub-second times like -i 0.1.
	  -n <db>            Database number.
	  -x                 Read last argument from STDIN.
	  -d <delimiter>     Multi-bulk delimiter in for raw formatting (default: \n).
	  -c                 Enable cluster mode (follow -ASK and -MOVED redirections).
	  --raw              Use raw formatting for replies (default when STDOUT is
	                     not a tty).
	  --no-raw           Force formatted output even when STDOUT is not a tty.
	  --csv              Output in CSV format.
	  --stat             Print rolling stats about server: mem, clients, ...
	  --latency          Enter a special mode continuously sampling latency.
	  --latency-history  Like --latency but tracking latency changes over time.
	                     Default time interval is 15 sec. Change it using -i.
	  --latency-dist     Shows latency as a spectrum, requires xterm 256 colors.
	                     Default time interval is 1 sec. Change it using -i.
	  --lru-test <keys>  Simulate a cache workload with an 80-20 distribution.
	  --slave            Simulate a slave showing commands received from the master.
	  --rdb <filename>   Transfer an RDB dump from remote server to local file.
	  --pipe             Transfer raw Redis protocol from stdin to server.
	  --pipe-timeout <n> In --pipe mode, abort with error if after sending all data.
	                     no reply is received within <n> seconds.
	                     Default timeout: 30. Use 0 to wait forever.
	  --bigkeys          Sample Redis keys looking for big keys.
	  --scan             List all keys using the SCAN command.
	  --pattern <pat>    Useful with --scan to specify a SCAN pattern.
	  --intrinsic-latency <sec> Run a test to measure intrinsic system latency.
	                     The test will run for the specified amount of seconds.
	  --eval <file>      Send an EVAL command using the Lua script at <file>.
	  --ldb              Used with --eval enable the Redis Lua debugger.
	  --ldb-sync-mode    Like --ldb but uses the synchronous Lua debugger, in
	                     this mode the server is blocked and script changes are
	                     are not rolled back from the server memory.
	  --help             Output this help and exit.
	  --version          Output version and exit.

	Examples:
	  cat /etc/passwd | redis-cli -x set mypasswd
	  redis-cli get mypasswd
	  redis-cli -r 100 lpush mylist x
	  redis-cli -r 100 -i 1 info | grep used_memory_human:
	  redis-cli --eval myscript.lua key1 key2 , arg1 arg2 arg3
	  redis-cli --scan --pattern '*:12345*'

	  (Note: when using --eval the comma separates KEYS[] from ARGV[] items)

	When no command is given, redis-cli starts in interactive mode.
	Type "help" in interactive mode for information on available commands
	and settings.

	[root@CentOS profile.d]# redis-cli 
	127.0.0.1:6379> SELECT 0         --> redis支持16个库 从0-15 
	OK
	127.0.0.1:6379> SELECT 15
	OK
	127.0.0.1:6379[15]> SELECT 22
	(error) ERR invalid DB index

使用通用帮助
  127.0.0.1:6379[15]> help @generic

  DEL key [key ...]
  summary: Delete a key
  since: 1.0.0

  DUMP key
  summary: Return a serialized version of the value stored at the specified key.
  since: 2.6.0

  EXISTS key [key ...]
  summary: Determine if a key exists
  since: 1.0.0

  EXPIRE key seconds
  summary: Set a key's time to live in seconds
  since: 1.0.0

  EXPIREAT key timestamp
  summary: Set the expiration for a key as a UNIX timestamp
  since: 1.2.0

  KEYS pattern
  summary: Find all keys matching the given pattern
  since: 1.0.0

  MIGRATE host port key| destination-db timeout [COPY] [REPLACE] [KEYS key]
  summary: Atomically transfer a key from a Redis instance to another one.
  since: 2.6.0

  MOVE key db
  summary: Move a key to another database
  since: 1.0.0

  OBJECT subcommand [arguments [arguments ...]]
  summary: Inspect the internals of Redis objects
  since: 2.2.3

  PERSIST key
  summary: Remove the expiration from a key
  since: 2.2.0

  PEXPIRE key milliseconds
  summary: Set a key's time to live in milliseconds
  since: 2.6.0

  PEXPIREAT key milliseconds-timestamp
  summary: Set the expiration for a key as a UNIX timestamp specified in milliseconds
  since: 2.6.0

  PTTL key
  summary: Get the time to live for a key in milliseconds
  since: 2.6.0

  RANDOMKEY -
  summary: Return a random key from the keyspace
  since: 1.0.0

  RENAME key newkey
  summary: Rename a key
  since: 1.0.0

  RENAMENX key newkey
  summary: Rename a key, only if the new key does not exist
  since: 1.0.0

  RESTORE key ttl serialized-value [REPLACE]
  summary: Create a key using the provided serialized value, previously obtained using DUMP.
  since: 2.6.0

  SCAN cursor [MATCH pattern] [COUNT count]
  summary: Incrementally iterate the keys space
  since: 2.8.0

  SORT key [BY pattern] [LIMIT offset count] [GET pattern [GET pattern ...]] [ASC|DESC] [ALPHA] [STORE destination]
  summary: Sort the elements in a list, set or sorted set
  since: 1.0.0

  TTL key
  summary: Get the time to live for a key
  since: 1.0.0

  TYPE key
  summary: Determine the type stored at key
  since: 1.0.0

  WAIT numslaves timeout
  summary: Wait for the synchronous replication of all the write commands sent in the context of the current connection
  since: 3.0.0

  PSYNC arg arg arg 
  summary: Help not available
  since: not known

  TOUCH key arg ...options...
  summary: Help not available
  since: not known

  SUBSTR key arg arg arg 
  summary: Help not available
  since: not known

  PFSELFTEST arg 
  summary: Help not available
  since: not known

  LATENCY arg arg ...options...
  summary: Help not available
  since: not known

  GEORADIUSBYMEMBER_RO key arg arg arg arg ...options...
  summary: Help not available
  since: not known

  REPLCONF arg ...options...
  summary: Help not available
  since: not known

  PFDEBUG arg arg arg ...options...
  summary: Help not available
  since: not known

  ASKING arg 
  summary: Help not available
  since: not known

  RESTORE-ASKING key arg arg arg ...options...
  summary: Help not available
  since: not known

  HOST: arg ...options...
  summary: Help not available
  since: not known

  GEORADIUS_RO key arg arg arg arg arg ...options...
  summary: Help not available
  since: not known

  POST arg ...options...
  summary: Help not available
  since: not known


使用帮助查看@string

  127.0.0.1:6379[15]> help @string

  APPEND key value
  summary: Append a value to a key
  since: 2.0.0

  BITCOUNT key [start end]
  summary: Count set bits in a string
  since: 2.6.0

  BITFIELD key [GET type offset] [SET type offset value] [INCRBY type offset increment] [OVERFLOW WRAP|SAT|FAIL]
  summary: Perform arbitrary bitfield integer operations on strings
  since: 3.2.0

  BITOP operation destkey key [key ...]
  summary: Perform bitwise operations between strings
  since: 2.6.0

  BITPOS key bit [start] [end]
  summary: Find first bit set or clear in a string
  since: 2.8.7

  DECR key
  summary: Decrement the integer value of a key by one
  since: 1.0.0

  DECRBY key decrement
  summary: Decrement the integer value of a key by the given number
  since: 1.0.0

  GET key
  summary: Get the value of a key
  since: 1.0.0

  GETBIT key offset
  summary: Returns the bit value at offset in the string value stored at key
  since: 2.2.0

  GETRANGE key start end
  summary: Get a substring of the string stored at a key
  since: 2.4.0

  GETSET key value
  summary: Set the string value of a key and return its old value
  since: 1.0.0

  INCR key
  summary: Increment the integer value of a key by one
  since: 1.0.0

  INCRBY key increment
  summary: Increment the integer value of a key by the given amount
  since: 1.0.0

  INCRBYFLOAT key increment
  summary: Increment the float value of a key by the given amount
  since: 2.6.0

  MGET key [key ...]
  summary: Get the values of all the given keys
  since: 1.0.0

  MSET key value [key value ...]
  summary: Set multiple keys to multiple values
  since: 1.0.1

  MSETNX key value [key value ...]
  summary: Set multiple keys to multiple values, only if none of the keys exist
  since: 1.0.1

  PSETEX key milliseconds value
  summary: Set the value and expiration in milliseconds of a key
  since: 2.6.0

  SET key value [EX seconds] [PX milliseconds] [NX|XX]
  summary: Set the string value of a key
  since: 1.0.0

  SETBIT key offset value
  summary: Sets or clears the bit at offset in the string value stored at key
  since: 2.2.0

  SETEX key seconds value
  summary: Set the value and expiration of a key
  since: 2.0.0

  SETNX key value
  summary: Set the value of a key, only if the key does not exist
  since: 1.0.0

  SETRANGE key offset value
  summary: Overwrite part of a string at key starting at the specified offset
  since: 2.2.0

  STRLEN key
  summary: Get the length of the value stored in a key
  since: 2.2.0  

  string 的增删改查:
  127.0.0.1:6379[15]> SETNX mykey 'hello redis'
	(integer) 1
	127.0.0.1:6379[15]> set mykey 'hello redis'          --> SET 即能增加也能修改
	OK
	127.0.0.1:6379[15]> get mykey                        --> GET 是查看当前KEY
	"hello redis"
	127.0.0.1:6379[15]> APPEND mykey ', www.redis.io'    --> APPEND 是在此KEY里添加内容
	(integer) 25
	127.0.0.1:6379[15]> get mykey
	"hello redis, www.redis.io"
	127.0.0.1:6379[15]> STRLEN mykey
	(integer) 25
	127.0.0.1:6379[15]> SETNX mykey 'hi redis;           --> SETNX是一旦此KEY有已存在就不会创建
	Invalid argument(s)
	127.0.0.1:6379[15]> SETNX mykey 'hi redis'
	(integer) 0
	127.0.0.1:6379[15]> get mykey
	"hello redis, www.redis.io"
	127.0.0.1:6379[15]> set count 0
	OK
	127.0.0.1:6379[15]> INCR count                       --> INCR KEY  把KEY里的数值自增,默认是自增+1
	(integer) 1
	127.0.0.1:6379[15]> INCR count
	(integer) 2
	127.0.0.1:6379[15]> INCR count
	(integer) 3
	127.0.0.1:6379[15]> INCRBY count 2                   --> INCRBY KEY 把KEY里的值自定义自增值的基数,在KEY后加值
	(integer) 5
	127.0.0.1:6379[15]> INCRBY count 2
	(integer) 7
	127.0.0.1:6379[15]> INCRBY count 2
	(integer) 9
	127.0.0.1:6379[15]> DECR count                       --> DECR  KEY  自减
	(integer) 8
	127.0.0.1:6379[15]> DECR count
	(integer) 7
	127.0.0.1:6379[15]> DECRBY count 2                   --> DECRBY KEY 自定义自减
	(integer) 5
	127.0.0.1:6379[15]> DECRBY count 2
	(integer) 3
	127.0.0.1:6379[15]> get count
	"3"
	127.0.0.1:6379[15]> del count                        --> DEL KEY 删除KEY
	(integer) 1
	127.0.0.1:6379[15]> get count
	(nil)
	127.0.0.1:6379[15]> set mykey 'hi redis'             --> 创建的KEY值为 'hi redis'
	OK
	127.0.0.1:6379[15]> get mykey
	"hi redis"
	127.0.0.1:6379[15]> set mykey 'welcome to my redis'  --> 修改KEY值为'welcome...' (SET如果KEY已存在就是直接修改KEY)
	OK
	127.0.0.1:6379[15]> get mykey
	"welcome to my redis"


查看帮助List
	127.0.0.1:6379[15]> help @list

	  BLPOP key [key ...] timeout
	  summary: Remove and get the first element in a list, or block until one is available
	  since: 2.0.0

	  BRPOP key [key ...] timeout
	  summary: Remove and get the last element in a list, or block until one is available
	  since: 2.0.0

	  BRPOPLPUSH source destination timeout
	  summary: Pop a value from a list, push it to another list and return it; or block until one is available
	  since: 2.2.0

	  LINDEX key index                                       
	  summary: Get an element from a list by its index
	  since: 1.0.0

	  LINSERT key BEFORE|AFTER pivot value
	  summary: Insert an element before or after another element in a list
	  since: 2.2.0

	  LLEN key
	  summary: Get the length of a list
	  since: 1.0.0

	  LPOP key
	  summary: Remove and get the first element in a list
	  since: 1.0.0

	  LPUSH key value [value ...]                              --> Lpush 命令将一个或多个值插入到列表头部          
	  summary: Prepend one or multiple values to a list
	  since: 1.0.0

	  LPUSHX key value
	  summary: Prepend a value to a list, only if the list exists
	  since: 2.2.0

	  LRANGE key start stop
	  summary: Get a range of elements from a list
	  since: 1.0.0

	  LREM key count value
	  summary: Remove elements from a list
	  since: 1.0.0

	  LSET key index value
	  summary: Set the value of an element in a list by its index
	  since: 1.0.0

	  LTRIM key start stop
	  summary: Trim a list to the specified range
	  since: 1.0.0

	  RPOP key
	  summary: Remove and get the last element in a list
	  since: 1.0.0

	  RPOPLPUSH source destination
	  summary: Remove the last element in a list, prepend it to another list and return it
	  since: 1.2.0

	  RPUSH key value [value ...]
	  summary: Append one or multiple values to a list
	  since: 1.0.0

	  RPUSHX key value
	  summary: Append a value to a list, only if the list exists
	  since: 2.2.0


  使用示例:
      127.0.0.1:6379[15]> LPUSH weekdays sat
		(integer) 1
		127.0.0.1:6379[15]> LPUSH weekdays Fri
		(integer) 2
		127.0.0.1:6379[15]> LPUSH weekdays Thu
		(integer) 3
		127.0.0.1:6379[15]> LINDEX weekdays 0     -->查看索引 weekdays 
		"Thu"
		127.0.0.1:6379[15]> LINDEX weekdays 1
		"Fri"
		127.0.0.1:6379[15]> LINDEX weekdays 2
		"sat"
		127.0.0.1:6379[15]> LPUSHX weekdays Tue   --> LPUSHX
		(integer) 4
		127.0.0.1:6379[15]> LINSERT weekdays BEFORE Tue Wed  --> 在Tue的索引前插入一个Wed的键值  BEFORE(前)|AFTER(后)
		(integer) 5
		127.0.0.1:6379[15]> LRANGE weekdays 0 4   -->查看范围的KEY值
		1) "Wed"
		2) "Tue"
		3) "Thu"
		4) "Fri"
		5) "sat"

		127.0.0.1:6379[15]> LRANGE weekdays 0 4
		1) "Wed"
		2) "Tue"
		3) "Thu"
		4) "Fri"
		5) "sat"
		127.0.0.1:6379[15]> LPOP weekdays         --> 删除从左开始的KEY值 默认删除一个
		"Wed"
		127.0.0.1:6379[15]> LRANGE weekdays 0 4
		1) "Tue"
		2) "Thu"
		3) "Fri"
		4) "sat"
		127.0.0.1:6379[15]> RPOP weekdays         --> 删除从右开始的KEY值,默认删除一个
		"sat"
		127.0.0.1:6379[15]> LRANGE weekdays 0 4
		1) "Tue"
		2) "Thu"
		3) "Fri"

		127.0.0.1:6379[15]> LREM weekdays 2 Tue   --> 删除指定键值
		(integer) 1
		127.0.0.1:6379[15]> LRANGE weekdays 0 4
		1) "Thu"
		2) "Fri"
		127.0.0.1:6379[15]> LLEN weekdays


帮助查看hash
    127.0.0.1:6379[15]> help @hash

	  HDEL key field [field ...]
	  summary: Delete one or more hash fields
	  since: 2.0.0

	  HEXISTS key field
	  summary: Determine if a hash field exists
	  since: 2.0.0

	  HGET key field
	  summary: Get the value of a hash field
	  since: 2.0.0

	  HGETALL key
	  summary: Get all the fields and values in a hash
	  since: 2.0.0

	  HINCRBY key field increment
	  summary: Increment the integer value of a hash field by the given number
	  since: 2.0.0

	  HINCRBYFLOAT key field increment
	  summary: Increment the float value of a hash field by the given amount
	  since: 2.6.0

	  HKEYS key
	  summary: Get all the fields in a hash
	  since: 2.0.0

	  HLEN key
	  summary: Get the number of fields in a hash
	  since: 2.0.0

	  HMGET key field [field ...]
	  summary: Get the values of all the given hash fields
	  since: 2.0.0

	  HMSET key field value [field value ...]
	  summary: Set multiple hash fields to multiple values
	  since: 2.0.0

	  HSCAN key cursor [MATCH pattern] [COUNT count]
	  summary: Incrementally iterate hash fields and associated values
	  since: 2.8.0

	  HSET key field value
	  summary: Set the string value of a hash field
	  since: 2.0.0

	  HSETNX key field value
	  summary: Set the value of a hash field, only if the field does not exist
	  since: 2.0.0

	  HSTRLEN key field
	  summary: Get the length of the value of a hash field
	  since: 3.2.0

	  HVALS key
	  summary: Get all the values in a hash
	  since: 2.0.0		

	示例:
	    127.0.0.1:6379[15]> HMSET member name jerry age 17 gender female    -->创建多个KEY的关联数组值 
		OK
		127.0.0.1:6379[15]> HKEYS member       --> 查看key里的键值对
		1) "name"
		2) "age"
		3) "gender"
		127.0.0.1:6379[15]> HVALS member       --> 查看KEY里的键值
		1) "jerry"
		2) "17"
		3) "female"
		127.0.0.1:6379[15]> HSTRLEN member name   --> 查看键值对 name里值的字符串长度
		(integer) 5  
		127.0.0.1:6379[15]> HGETALL member
		1) "name"
		2) "jerry"
		3) "age"
		4) "17"
		5) "gender"
		6) "female"


查看SET的帮助列表

    127.0.0.1:6379> HELP @SET

	  SADD key member [member ...]
	  summary: Add one or more members to a set
	  since: 1.0.0

	  SCARD key
	  summary: Get the number of members in a set
	  since: 1.0.0

	  SDIFF key [key ...]                   -->对比两个KEY值的差异部分 (前后顺序的KEY值放置得到的值也不一样)
	  summary: Subtract multiple sets
	  since: 1.0.0

	  SDIFFSTORE destination key [key ...]
	  summary: Subtract multiple sets and store the resulting set in a key
	  since: 1.0.0

	  SINTER key [key ...]                  --> 对比两个KEY值的交集部分
	  summary: Intersect multiple sets
	  since: 1.0.0

	  SINTERSTORE destination key [key ...]
	  summary: Intersect multiple sets and store the resulting set in a key
	  since: 1.0.0

	  SISMEMBER key member
	  summary: Determine if a given value is a member of a set
	  since: 1.0.0

	  SMEMBERS key
	  summary: Get all the members in a set
	  since: 1.0.0

	  SMOVE source destination member
	  summary: Move a member from one set to another
	  since: 1.0.0

	  SPOP key [count]          --> 随机移除KEY值里的值
	  summary: Remove and return one or multiple random members from a set
	  since: 1.0.0

	  SRANDMEMBER key [count]
	  summary: Get one or multiple random members from a set
	  since: 1.0.0

	  SREM key member [member ...]              --> 指定移除KEY值里的值
	  summary: Remove one or more members from a set
	  since: 1.0.0

	  SSCAN key cursor [MATCH pattern] [COUNT count]
	  summary: Incrementally iterate Set elements
	  since: 2.8.0

	  SUNION key [key ...]                      --> 对两个KEY值进行集合汇总
	  summary: Add multiple sets
	  since: 1.0.0

	  SUNIONSTORE destination key [key ...]
	  summary: Add multiple sets and store the resulting set in a key
	  since: 1.0.0


查看帮助SORTED_SET
    127.0.0.1:6379> HELP @sorted_set

	  ZADD key [NX|XX] [CH] [INCR] score member [score member ...]
	  summary: Add one or more members to a sorted set, or update its score if it already exists
	  since: 1.2.0

	  ZCARD key
	  summary: Get the number of members in a sorted set
	  since: 1.2.0

	  ZCOUNT key min max
	  summary: Count the members in a sorted set with scores within the given values
	  since: 2.0.0

	  ZINCRBY key increment member
	  summary: Increment the score of a member in a sorted set
	  since: 1.2.0

	  ZINTERSTORE destination numkeys key [key ...] [WEIGHTS weight] [AGGREGATE SUM|MIN|MAX]
	  summary: Intersect multiple sorted sets and store the resulting sorted set in a new key
	  since: 2.0.0

	  ZLEXCOUNT key min max
	  summary: Count the number of members in a sorted set between a given lexicographical range
	  since: 2.8.9

	  ZRANGE key start stop [WITHSCORES]
	  summary: Return a range of members in a sorted set, by index
	  since: 1.2.0

	  ZRANGEBYLEX key min max [LIMIT offset count]
	  summary: Return a range of members in a sorted set, by lexicographical range
	  since: 2.8.9

	  ZRANGEBYSCORE key min max [WITHSCORES] [LIMIT offset count]
	  summary: Return a range of members in a sorted set, by score
	  since: 1.0.5

	  ZRANK key member
	  summary: Determine the index of a member in a sorted set
	  since: 2.0.0

	  ZREM key member [member ...]
	  summary: Remove one or more members from a sorted set
	  since: 1.2.0

	  ZREMRANGEBYLEX key min max
	  summary: Remove all members in a sorted set between the given lexicographical range
	  since: 2.8.9

	  ZREMRANGEBYRANK key start stop
	  summary: Remove all members in a sorted set within the given indexes
	  since: 2.0.0

	  ZREMRANGEBYSCORE key min max
	  summary: Remove all members in a sorted set within the given scores
	  since: 1.2.0

	  ZREVRANGE key start stop [WITHSCORES]
	  summary: Return a range of members in a sorted set, by index, with scores ordered from high to low
	  since: 1.2.0

	  ZREVRANGEBYLEX key max min [LIMIT offset count]
	  summary: Return a range of members in a sorted set, by lexicographical range, ordered from higher to lower strings.
	  since: 2.8.9

	  ZREVRANGEBYSCORE key max min [WITHSCORES] [LIMIT offset count]
	  summary: Return a range of members in a sorted set, by score, with scores ordered from high to low
	  since: 2.2.0

	  ZREVRANK key member
	  summary: Determine the index of a member in a sorted set, with scores ordered from high to low
	  since: 2.0.0

	  ZSCAN key cursor [MATCH pattern] [COUNT count]
	  summary: Incrementally iterate sorted sets elements and associated scores
	  since: 2.8.0

	  ZSCORE key member
	  summary: Get the score associated with the given member in a sorted set
	  since: 1.2.0

	  ZUNIONSTORE destination numkeys key [key ...] [WEIGHTS weight] [AGGREGATE SUM|MIN|MAX]
	  summary: Add multiple sorted sets and store the resulting sorted set in a new key


查看连接的帮助

    
	127.0.0.1:6379> help @connection

	  AUTH password
	  summary: Authenticate to the server
	  since: 1.0.0

	  ECHO message
	  summary: Echo the given string
	  since: 1.0.0

	  PING [message]
	  summary: Ping the server
	  since: 1.0.0

	  QUIT -
	  summary: Close the connection
	  since: 1.0.0

	  SELECT index
	  summary: Change the selected database for the current connection
	  since: 1.0.0

    redis-cli命令：
		Usage: redis-cli [OPTIONS] [cmd [arg [arg ...]]]
			
			-h HOST
			-p PORT
			-a PASSWORD
			-n DBID
                0-15

		清空数据库：
			 FLUSHDB：Remove all keys from the current database
				清空当前数据库；
			 FLUSHALL：Remove all keys from all databases
				清空所有数据库；

redis的配置文档

		[root@CentOS ~]# grep "^###" /etc/redis.conf 
		################################## INCLUDES ###################################         ----> 包含的文件
		################################## NETWORK #####################################        ----> 网络工作配置
		################################# GENERAL #####################################         ----> 一般配置
		################################ SNAPSHOTTING  ################################         ----> 快照相关的配置
		################################# REPLICATION #################################         
		################################## SECURITY ###################################         ----> 安全相关
		################################### LIMITS ####################################         ----> 限制相关配置
		############################## APPEND ONLY MODE ###############################         ---->
		################################ LUA SCRIPTING  ###############################
		################################ REDIS CLUSTER  ###############################         ----> cluster 相关配置
		################################## SLOW LOG ###################################         ----> 日志相关
		################################ LATENCY MONITOR ##############################
		############################# EVENT NOTIFICATION ##############################         ----> 事件通知
		############################### ADVANCED CONFIG ###############################



        一般性相关配置:
        ################################# GENERAL #####################################

		# By default Redis does not run as a daemon. Use 'yes' if you need it.
		# Note that Redis will write a pid file in /var/run/redis.pid when daemonized.
		daemonize no

		# If you run Redis from upstart or systemd, Redis can interact with your
		# supervision tree. Options:
		#   supervised no      - no supervision interaction
		#   supervised upstart - signal upstart by putting Redis into SIGSTOP mode
		#   supervised systemd - signal systemd by writing READY=1 to $NOTIFY_SOCKET
		#   supervised auto    - detect upstart or systemd method based on
		#                        UPSTART_JOB or NOTIFY_SOCKET environment variables
		# Note: these supervision methods only signal "process is ready."
		#       They do not enable continuous liveness pings back to your supervisor.
		supervised no

		...

		# Set the number of databases. The default database is DB 0, you can select
		# a different one on a per-connection basis using SELECT <dbid> where
		# dbid is a number between 0 and 'databases'-1
		databases 16                 --> 控制键值的数量的.一般16个够用了

		...


		网络相关的配置 

		################################## NETWORK #####################################

		# By default, if no "bind" configuration directive is specified, Redis listens
		# for connections from all the network interfaces available on the server.
		# It is possible to listen to just one or multiple selected interfaces using
		# the "bind" configuration directive, followed by one or more IP addresses.
		#
		# Examples:
		#
		# bind 192.168.1.100 10.0.0.1
		# bind 127.0.0.1 ::1
		#
		# ~~~ WARNING ~~~ If the computer running Redis is directly exposed to the
		# internet, binding to all the interfaces is dangerous and will expose the
		# instance to everybody on the internet. So by default we uncomment the
		# following bind directive, that will force Redis to listen only into
		# the IPv4 lookback interface address (this means Redis will be able to
		# accept connections only from clients running into the same computer it
		# is running).
		#
		# IF YOU ARE SURE YOU WANT YOUR INSTANCE TO LISTEN TO ALL THE INTERFACES
		# JUST COMMENT THE FOLLOWING LINE.
		# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
		bind 127.0.0.1    --> 是这监听的地址,如果想监听所有地址使用 bind 0.0.0.0
        
        # Protected mode is a layer of security protection, in order to avoid that
		# Redis instances left open on the internet are accessed and exploited.
		#
		# When protected mode is on and if:
		#
		# 1) The server is not binding explicitly to a set of addresses using the
		#    "bind" directive.
		# 2) No password is configured.
		#
		# The server only accepts connections from clients connecting from the
		# IPv4 and IPv6 loopback addresses 127.0.0.1 and ::1, and from Unix domain
		# sockets.
		#
		# By default protected mode is enabled. You should disable it only if
		# you are sure you want clients from other hosts to connect to Redis
		# even if no authentication is configured, nor a specific set of interfaces
		# are explicitly listed using the "bind" directive.
		protected-mode yes      --> 启用保护模式

		# Accept connections on the specified port, default is 6379 (IANA #815344).
		# If port 0 is specified Redis will not listen on a TCP socket.
		port 6379               --> 监听端口


		安全相关的配置
		################################## SECURITY ###################################

		# Require clients to issue AUTH <PASSWORD> before processing any other
		# commands.  This might be useful in environments in which you do not trust
		# others with access to the host running redis-server.
		#
		# This should stay commented out for backward compatibility and because most
		# people do not need auth (e.g. they run their own servers).
		#
		# Warning: since Redis is pretty fast an outside user can try up to
		# 150k passwords per second against a good box. This means that you should
		# use a very strong password otherwise it will be very easy to break.
		#
		# requirepass foobared       --> 这里是设置密码的   设置密码后需要在 redis-cli -a foobared 指定密码或进入redis-cli命令行后 AUTH PASSWORD

		# Command renaming.
		#
		# It is possible to change the name of dangerous commands in a shared
		# environment. For instance the CONFIG command may be renamed into something
		# hard to guess so that it will still be available for internal-use tools
		# but not available for general clients.
		#
		# Example:
		#
		# rename-command CONFIG b840fc02d524045429941cc15f59e41cb7be6c52    -->重命名CONFIG的危险命令
		#
		# It is also possible to completely kill a command by renaming it into
		# an empty string:
		#
		# rename-command CONFIG ""
		#
		# Please note that changing the name of commands that are logged into the
		# AOF file or transmitted to slaves may cause problems.


        限制相关的配置
        ################################### LIMITS ####################################

		# Set the max number of connected clients at the same time. By default
		# this limit is set to 10000 clients, however if the Redis server is not
		# able to configure the process file limit to allow for the specified limit
		# the max number of allowed clients is set to the current file limit
		# minus 32 (as Redis reserves a few file descriptors for internal uses).
		#
		# Once the limit is reached Redis will close all the new connections sending
		# an error 'max number of clients reached'.
		#
		# maxclients 10000        --> 最大的并发连接数 默认是10000

		# Don't use more memory than the specified amount of bytes.
		# When the memory limit is reached Redis will try to remove keys
		# according to the eviction policy selected (see maxmemory-policy).
		#
		# If Redis can't remove keys according to the policy, or if the policy is
		# set to 'noeviction', Redis will start to reply with errors to commands
		# that would use more memory, like SET, LPUSH, and so on, and will continue
		# to reply to read-only commands like GET.
		#
		# This option is usually useful when using Redis as an LRU cache, or to set
		# a hard memory limit for an instance (using the 'noeviction' policy).
		#
		# WARNING: If you have slaves attached to an instance with maxmemory on,
		# the size of the output buffers needed to feed the slaves are subtracted
		# from the used memory count, so that network problems / resyncs will
		# not trigger a loop where keys are evicted, and in turn the output
		# buffer of slaves is full with DELs of keys evicted triggering the deletion
		# of more keys, and so forth until the database is completely emptied.
		#
		# In short... if you have slaves attached it is suggested that you set a lower
		# limit for maxmemory so that there is some free RAM on the system for slave
		# output buffers (but this is not needed if the policy is 'noeviction').
		#
		# maxmemory <bytes>         -->设置使用的内存使用量 最好设置个定量,一般设置70% 最好不要激活交换内存
         
        # MAXMEMORY POLICY: how Redis will select what to remove when maxmemory
		# is reached. You can select among five behaviors:
		#
		# volatile-lru -> remove the key with an expire set using an LRU algorithm    --> 如果某一个键设置了EX过期时间的,将会进行淘汰 如:set mykey 'haha' EX 10 
		# allkeys-lru -> remove any key according to the LRU algorithm                --> 
		# volatile-random -> remove a random key with an expire set                   --> 随机淘汰掉有过期时间的
		# allkeys-random -> remove a random key, any key                              --> 随机淘汰一个键里的所有键值
		# volatile-ttl -> remove the key with the nearest expire time (minor TTL)     --> 把设置了过期时间及快要过期的KEY进行淘汰
		# noeviction -> don't expire at all, just return an error on write operations --> 不淘汰任何项
		#
		# Note: with any of the above policies, Redis will return an error on write
		#       operations, when there are no suitable keys for eviction.
		#
		#       At the date of writing these commands are: set setnx setex append
		#       incr decr rpush lpush rpushx lpushx linsert lset rpoplpush sadd
		#       sinter sinterstore sunion sunionstore sdiff sdiffstore zadd zincrby
		#       zunionstore zinterstore hset hsetnx hmset hincrby incrby decrby
		#       getset mset msetnx exec sort
		#
		# The default is:
		#
		# maxmemory-policy noeviction        --> 当内存使用达到一定的量时进行淘汰机制  最好使用 volatile-lru        其次volatile-random


 		# LRU and minimal TTL algorithms are not precise algorithms but approximated
		# algorithms (in order to save memory), so you can tune it for speed or
		# accuracy. For default Redis will check five keys and pick the one that was
		# used less recently, you can change the sample size using the following
		# configuration directive.
		#
		# The default of 5 produces good enough results. 10 Approximates very closely
		# true LRU but costs a bit more CPU. 3 is very fast but not very accurate.
		#
		# maxmemory-samples 5                -->采样比例,如果使用的是volatile-lru淘汰机制的话从中采样5个进行LRU算法淘汰


	SLOW LOG的设置

		################################## SLOW LOG ###################################

		# The Redis Slow Log is a system to log queries that exceeded a specified
		# execution time. The execution time does not include the I/O operations
		# like talking with the client, sending the reply and so forth,
		# but just the time needed to actually execute the command (this is the only
		# stage of command execution where the thread is blocked and can not serve
		# other requests in the meantime).
		#
		# You can configure the slow log with two parameters: one tells Redis
		# what is the execution time, in microseconds, to exceed in order for the
		# command to get logged, and the other parameter is the length of the
		# slow log. When a new command is logged the oldest one is removed from the
		# queue of logged commands.

		# The following time is expressed in microseconds, so 1000000 is equivalent
		# to one second. Note that a negative number disables the slow log, while
		# a value of zero forces the logging of every command.
		slowlog-log-slower-than 10000

		# There is no limit to this length. Just be aware that it will consume memory.
		# You can reclaim memory used by the slow log with SLOWLOG RESET.
		slowlog-max-len 128

				SlowLog相关的配置:
			slowlog-log-slower-than 10000
				单位是微秒；
			slowlog-max-len 128
				SlowLog记录的日志最大条目；


	ADVANCED相关的配置
	    
	    ############################### ADVANCED CONFIG ###############################

		# Hashes are encoded using a memory efficient data structure when they have a
		# small number of entries, and the biggest entry does not exceed a given
		# threshold. These thresholds can be configured using the following directives.
		hash-max-ziplist-entries 512        --> 定义HASH 上限512个子键
		hash-max-ziplist-value 64           --> 子键的值最大不能超过64个字节
		                       设置ziplist的键数量最大值,每个值的最大空间.     调的话通常往小的调

		# Lists are also encoded in a special way to save a lot of space.
		# The number of entries allowed per internal list node can be specified
		# as a fixed maximum size or a maximum number of elements.
		# For a fixed maximum size, use -5 through -1, meaning:
		# -5: max size: 64 Kb  <-- not recommended for normal workloads
		# -4: max size: 32 Kb  <-- not recommended
		# -3: max size: 16 Kb  <-- probably not recommended
		# -2: max size: 8 Kb   <-- good
		# -1: max size: 4 Kb   <-- good
		# Positive numbers mean store up to _exactly_ that number of elements
		# per list node.
		# The highest performing option is usually -2 (8 Kb size) or -1 (4 Kb size),
		# but if your use case is unique, adjust the settings as necessary.
		list-max-ziplist-size -2

		# Lists may also be compressed.
		# Compress depth is the number of quicklist ziplist nodes from *each* side of
		# the list to *exclude* from compression.  The head and tail of the list
		# are always uncompressed for fast push/pop operations.  Settings are:
		# 0: disable all list compression
		# 1: depth 1 means "don't start compressing until after 1 node into the list,
		#    going from either the head or tail"
		#    So: [head]->node->node->...->node->[tail]
		#    [head], [tail] will always be uncompressed; inner nodes will compress.
		# 2: [head]->[next]->node->node->...->node->[prev]->[tail]
		#    2 here means: don't compress head or head->next or tail->prev or tail,
		#    but compress all nodes between them.
		# 3: [head]->[next]->[next]->node->node->...->node->[prev]->[prev]->[tail]
		# etc.
		list-compress-depth 0		
        ...
        # Both the hard or the soft limit can be disabled by setting them to zero.
		client-output-buffer-limit normal 0 0 0                 硬限制   软限制   软限制的超时时长
		client-output-buffer-limit slave 256mb 64mb 60          限制从 最大256MB 硬限制  64MB的软限制 60秒的超时时长
		client-output-buffer-limit pubsub 32mb 8mb 60


	redis-cli命令：
			 
		Server相关的命令：
			 CLIENT GETNAME      --> 连接redis的客户端命令
			 *CLIENT KILL        --> 杀掉客户端
				CLIENT KILL [ip:port] [ID client-id] [TYPE normal|master|slave|pubsub] [ADDR ip:port] [SKIPME yes/no]
			 *CLIENT LIST
			 CLIENT PAUSE
				CLIENT PAUSE timeout
			 CLIENT REPLY				
			 CLIENT SETNAME：Set the current connection name
			 
			  SHUTDOWN [NOSAVE|SAVE]
			  
             配置参数可运行时修改：
			 
                CONFIG GET
                CONFIG RESETSTAT
                CONFIG REWRITE
                CONFIG SET
			 
			 INFO：服务器状态信息查看；分为多个secion；
				INFO [section]  
				    section 有 cpu  memory cluster 等


	Redis的持久化:
		RDB：snapshotting, 二进制格式；按事先定制的策略，周期性地将数据从内存同步至磁盘；数据文件默认为dump.rdb；
			客户端显式使用SAVE或BGSAVE命令来手动启动快照保存机制；
				SAVE：同步，即在主线程中保存快照，此时会阻塞所有客户端请求；
				BGSAVE：异步；backgroud
		AOF：Append Only File, fsync
			记录每次写操作至指定的文件尾部实现的持久化；当redis重启时，可通过重新执行文件中的命令在内存中重建出数据库；
				BGREWRITEAOF：AOF文件重写；
					不会读取正在使用AOF文件，而是通过将内存中的数据以命令的方式保存至临时文件中，完成之后替换原来的AOF文件；

					--> AOF的重写就是 当一段数据不断变化重写时,我们只定义他的最后一次重写进行保存.如果保存后还有数据保存变化项,我们进行类似全量++的增量
                        如 我们定义 KEY 1000     我们定义最后一次保存  KEY = 1000   如果后期有增量 进行 1000 + 1  还有再加  然后再进行KEY的定义 KEY = 1003

				RDB相关的配置：
				*save <seconds> <changes>
				
					save 900 1          在900秒之内, 有1个键值变化就触发
					save 300 10         在300秒之内 有10次键值变化就触发
					save 60 10000       在60秒种之内 有10000次键值变化就触发保存至磁盘
					save 5  200000
					
					表示：三个策略满足其中任意一个均会触发SNAPSHOTTING操作；900s内至少有一个key有变化，300s内至少有10个key有变化，60s内至少有1W个key发生变化；
					      如果想手动进行触发使用 SAVE 或 BGSAVE

				ROB相关的配置:

					################################ SNAPSHOTTING  ################################
					#
					# Save the DB on disk:
					#
					#   save <seconds> <changes>
					#
					#   Will save the DB if both the given number of seconds and the given
					#   number of write operations against the DB occurred.
					#
					#   In the example below the behaviour will be to save:
					#   after 900 sec (15 min) if at least 1 key changed
					#   after 300 sec (5 min) if at least 10 keys changed
					#   after 60 sec if at least 10000 keys changed
					#
					#   Note: you can disable saving completely by commenting out all "save" lines.
					#
					#   It is also possible to remove all the previously configured save
					#   points by adding a save directive with a single empty string argument
					#   like in the following example:
					#
					#   save ""

					save 900 1
					save 300 10
					save 60 10000
		      
				    *appendonly no
					appendfilename "appendonly.aof"
				
				AOF相关的配置	 --> AOF没有ROB的效率高
					*appendfsync 
						Redis supports three different modes:
							no：redis不执行主动同步操作，而是OS进行；
							everysec：每秒一次；
							always：每语句一次；
							
					no-appendfsync-on-rewrite no
						是否在后台执行aof重写期间不调用fsync，默认为no，表示调用；
						
					auto-aof-rewrite-percentage 100
					auto-aof-rewrite-min-size 64mb	
						上述两个条件同时满足时，方会触发重写AOF；与上次aof文件大小相比，其增长量超过100%，且大小不少于64MB; 
						
					aof-load-truncated yes
					
				注意：持久机制本身不能取代备份；应该制订备份策略，对redis库定期备份；
				
				RDB与AOF同时启用： 
					(1) BGSAVE和BGREWRITEAOF不会同时进行；
					(2) Redis服务器启动时用持久化的数据文件恢复数据，会优先使用AOF；
		
    复制：(主从)
		特点：
			一个Master可以有多个slave主机，支持链式复制；
			Master以非阻塞方式同步数据至slave主机；
			
		配置slave节点：
			redis-cli> SLAVEOF <MASTER_IP> <MASTER_PORT>
			redis-cli> CONFIG SET masterauth <PASSWORD>
			
		配置参数：
			*slaveof
			*masterauth 
			
			slave-serve-stale-data yes
			slave-read-only yes
			*repl-diskless-sync no
				no, Disk-backed, Diskless
				
				新的从节点或某较长时间未能与主节点进行同步的从节点重新与主节点通信，需要做“full synchronization"，此时其同步方式有两种style：
					Disk-backend：主节点新创建快照文件于磁盘中，而后将其发送给从节点；
					Diskless：主节占新创建快照后直接通过网络套接字文件发送给从节点；为了实现并行复制，通常需要在复制启动前延迟一个时间段；
			
			repl-diskless-sync-delay 5
			repl-ping-slave-period 10
			
			*repl-timeout 60
			
			repl-disable-tcp-nodelay no
			repl-backlog-size 1mb
			
			*slave-priority 100
				复制集群中，主节点故障时，sentinel应用场景中的主节点选举时使用的优先级；数字越小优先级越高，但0表示不参与选举； 
			
			min-slaves-to-write 3：主节点仅允许其能够通信的从节点数量大于等于此处的值时接受写操作；
			min-slaves-max-lag 10：从节点延迟时长超出此处指定的时长时，主节点会拒绝写入操作；				

        主从节点配置示例:

            node1# ntpdata 172.18.0.1     主节点: 192.168.3.11
            node2# ntpdata 172.18.0.1     从节点: 192.168.3.20
            node3# ntpdata 172.18.0.1     从节点: 192.168.3.21

          node1:配置

            ################################## NETWORK #####################################
            bind 0.0.0.0
            ################################## SECURITY ###################################
            requirepass ilinux

          node2:配置  
            ################################## NETWORK #####################################
            bind 0.0.0.0
            ################################## SECURITY ###################################
            requirepass ilinux
            ################################# REPLICATION #################################
            slaveof 192.168.3.11 6379
            masterauth ilinux

          node3:的配置和note2一样可以使用CONFIG 命令进行设置

              192.168.3.13:6379> SLAVEOF 192.168.3.13 6379
              192.168.3.13:6379> CONFIG SET masterauth ilinux
              192.168.3.13:6379> CONFIG REWRITE

          
            测试可以进入 redis-cli -h 192.168.3.21 
 			 redis-cli> SELECT 15    因为之前是在15号仓进行创建的KEYS
             redis-cli> KEYS *  查看主节点之前创建的KEYS  
             redis-cli> INFO     或者使用INFO进行查看主从信息 
             redis-cli> CLIENT LIST 如果从节点有连入进redis 可以查看到CLIENT里有从节点连接进来的新增客户端 cmd为replconf


    sentinel：
		主要完成三个功能：监控、通知、自动故障转移
		
			选举：流言协议、投票协议    能有投票权的节有得是基数

			  选举根根quorum 机制进行选举
                             with quorum : > total/2       quorum选举值 大于 节点总数/2 时 quorum则生效     (如果有3台选择节点,有两台证明主不能通信,则quorum值为2 那么2> 3/2所以生效)
                             withoout quorum : <= total/2          

			当redis的主挂掉了进行选举推荐一个新的主,类似于高可用keepalived
			
		配置项：
		    sentinel专用的配置文件 /etc/redis-sentinel.conf 专用的进程管理/usr/lib/systemd/system/redis-sentinel.service
			port 26379
			sentinel monitor <master-name> <ip> <redis-port> <quorum>
			    > sentinel monitor mymaster 127.0.0.1 6379 2      后面的2是quorum值
			
			sentinel auth-pass <master-name> <password>
			
				<quorum>表示sentinel集群的quorum机制，即至少有quorum个sentinel节点同时判定主节点故障时，才认为其真的故障；
					s_down: subjectively down
					o_down: objectively down
			
			sentinel down-after-milliseconds <master-name> <milliseconds>
				监控到指定的集群的主节点异常状态持续多久方才将标记为“故障”；
				
			sentinel parallel-syncs <master-name> <numslaves>
				当主节点down掉的时候,从节点全部要向新的主进行同步,一次同步几台机器.服务器压力过大可以少点{指在failover(故障转移)过程中，能够被sentinel并行配置的从节点的数量;}
				
			sentinel failover-timeout <master-name> <milliseconds>
				sentinel必须在此指定的时长内完成故障转移操作，否则，将视为故障转移操作失败；时间可以设置稍微长点 默认3分钟
				
			sentinel notification-script <master-name> <script-path>
				通知脚本，此脚本被自动传递多个参数；:
				
			redis-cli -h SENTINEL_HOST -p SENTINEL_PORT 
				redis-cli> 
					SENTINEL masters
					SENTINEL slaves <MASTER_NAME>
					SENTINEL failover <MASTER_NAME>
					SENTINEL get-master-addr-by-name <MASTER_NAME>         

                192.168.3.12:26379> masters        -->输入命令提示以下报错时,是因为/etc/redis-sentinel.conf没有配置绑定的地址 所以我们要在port 26379 下添加 bind 0.0.0.0或指定IP
				(error) DENIED Redis is running in protected mode because protected mode is enabled, no bind address was specified, no authentication password is requested to clients. In this mode connections are only accepted from the loopback interface. If you want to connect from external computers to Redis you may adopt one of the following solutions: 1) Just disable protected mode sending the command 'CONFIG SET protected-mode no' from the loopback interface by connecting to Redis from the same host the server is running, however MAKE SURE Redis is not publicly accessible from internet if you do so. Use CONFIG REWRITE to make this change permanent. 2) Alternatively you can just disable the protected mode by editing the Redis configuration file, and setting the protected mode option to 'no', and then restarting the server. 3) If you started the server manually just for testing, restart it with the '--protected-mode no' option. 4) Setup a bind address or an authentication password. NOTE: You only need to do one of the above things in order for the server to start accepting connections from the outside.
				192.168.3.12:26379> AUTH ilinux

        示例:sentinel

            主节点: 192.168.3.11 master
            从节点: 192.168.3.12
            从节点: 192.168.3.12

            主点节配置: vim /etc/redis-sentinel.conf
              port 26379            -->sentinel 端口
			  bind 0.0.0.0          -->绑定的IP
              sentinel monitor mymaster 192.168.3.11 6379 2      -->sentinel 监控的主名称及IP 端口 quorum值
              sentinel down-after-milliseconds mymaster 5000     -->sentinel 监控down掉多久事为masterdown掉  我们设置为5000为 5000ms 即5s 
              sentinel parallel-syncs mymaster 3                 -->当新主上线我们设置一次有多少从进行并行同步 我们设为3
              sentinel auth-pass mymaster ilinux                 -->sentinel 的验证密码为 ilinux
              # sentinel notification-script <master-name> <script-path>  --> 这项是当sentinel生效时,会运行脚本,我们可以把微信的脚本放这提示我们redis有改动 这项没做 待以后做

            然后把主的修改配置文件SCP 到各从节点并启动 systemctl start redis-sentinel.service  

              测试:
                192.168.3.11:26379> SENTINEL masters
                192.168.3.11:26379> SENTINEL slaves mymaster

              测试: stop 11 然后使用上面两个命令可以查看到集群里的redis 主从信息  

            当11的主节点修复后我们要进行配置文档的修改后重新上线
              
              先查看当前新主的IP是多少,然后再进行 slaveof 192.168.3.13 6379 的修改 然后启动服务重新上线  

    
    CLuster：
        集群相关的配置：

            cluster-enabled 是否开启集群配置  集群节点配置启动后会自己生成一个集群配置文件,保存着集群节点的信息
            cluster-config-file 集群节点集群信息配置文件,每个节点都有一个,由redis生成和更新,配置时避免名称冲突
            cluster-node-timeout 集群节点互连超时的阈值，单位毫秒
            cluster-slave-validity-factor 进行故障转移时,salve会申请成为master。有时slave会和master失联很久导致数据较旧，这样的slave不应该成为master。这个配置用来判断slave是否和master失联时间过长。
            # cluster-require-full-coverage yes   启用只有当所有槽对应上后才接受请求    注释默认

        配置过程：
            (1) 设置配置文件，启用集群功能；
            (2) 启动redis后为每个节点分配slots；
                CLUSTER ADDSLOTS
                注意：每个slot要独立创建；可用范围是0-16383，共16384个；
                
                    redis-cli -c -h 192.168.1.100 -p 7000 cluster addslots {0..5000}
            (3) 设定集群成员关系；
                CLUSTER MEET
                
        
        示例： CLUSTER 操作步骤

            1. 192.168.3.11    centos 7.3    redis 3.2.3.1
               192.168.3.12    centos 7.3    redis 3.2.3.1
               192.168.3.13    centos 7.3    redis 3.2.3.1


            2.配置文件编辑  vim /etc/redis.conf
              ################################## NETWORK #####################################
              bind 0.0.0.0
              ################################ REDIS CLUSTER  ###############################
              cluster-enabled yes
              cluster-config-file nodes-6379.conf
              cluster-node-timeout 15000

              由于想快速的编辑出，所以没做security设置  

            3. scp 配置好的redis.conf到其它主机上 
            
            4. 在192.168.3.11上划分槽点和添加CLUSTER主机
                 --------------------------这些配置在192.168.3.11主机上做----------------------------
               [root@localhost ~]# redis-cli -h 192.168.3.11 CLUSTER ADDSLOTS {0..5461} 
               [root@localhost ~]# redis-cli -h 192.168.3.12 CLUSTER ADDSLOTS {5462..10922}
               [root@localhost ~]# redis-cli -h 192.168.3.12 CLUSTER ADDSLOTS {10923..16383}

               -----------------------------↑↑↑ 上述为什么不在redis命令行做,因为redis-cli命令行需要把每个槽点一个一个的输进去例 5461个槽点 0 1 2 3 4 5 6 7 8... 不要在redis-cli命令行中添加槽点

               -----------------------------↓↓↓ 添加集群主机. CLUSTER INFO 可以查看到集群信息---------------------------------------------------------
               192.168.3.11:6379> CLUSTER MEET 192.168.3.12 6379
               ok
               192.168.3.11:6379> CLUSTER MEET 192.168.3.13 6379
               ok
               192.168.3.11:6379> CLUSTER INFO
				cluster_state:ok
				cluster_slots_assigned:16384
				cluster_slots_ok:16384
				cluster_slots_pfail:0
				cluster_slots_fail:0
				cluster_known_nodes:3
				cluster_size:2
				cluster_current_epoch:2
				cluster_my_epoch:1
				cluster_stats_messages_sent:21
				cluster_stats_messages_received:21
				192.168.3.11:6379> CLUSTER INFO
				cluster_state:ok
				cluster_slots_assigned:16384
            

	redis的集群技术：
		客户端分片
		代理分片：
			豌豆荚：codis
			twitter：twemproxy
		redis cluster
						
					
		博客作业：
			(1) replication, sentinel，cluster
			(2) rdb, aof 
			
		课外实践：
			(1) codis        redis 客户代理服务器
			(2) cerberus     redis 客户代理服务器
 			(3) predixy      redis 客户代理服务器
